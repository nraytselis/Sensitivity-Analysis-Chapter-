---
title: "Sensitivity Analysis"
output: html_document
date: "2025-11-11"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load required packages}
library(ggplot2)
library(cowplot)
theme_set(theme_cowplot()) # Makes the ggplot look nicer (says Dave)
library(tidyverse)
library(tidyr)
library(patchwork)
library(dplyr)
library(deSolve)
library(caTools) #this package is for AUC calculations
library(sensobol)
library(data.table)
library(foreach)
library(parallel)
library(doParallel)
library(Matrix)
library(pracma)
```


##Load model and compile from C
```{r load_model}
# compile model from C definition
#setwd("~/Desktop/Rscripts/Data/Fish/")
#try(dyn.unload("~/Desktop/Rscripts/Data/Fish/Fishing_Flooding_Model.so")) # unLoad dll, so for Mac
#system("R CMD SHLIB ~/Desktop/Rscripts/Data/Fish/Fishing_Flooding_Model.c")
#dyn.load("~/Desktop/Rscripts/Data/Fish/Fishing_Flooding_Model.so") # load dll
```


#Model in R
```{r}

Pond_ODE =function(t, y, parameters) {
  
  with(as.list(parameters),{
    N=y[1]; J=y[2]; A=y[3]; Es = y[4:(4+latent_stages - 1)]; I = y[4+latent_stages]; Preds = y[5+latent_stages]; L3F = y[6+latent_stages]; HEF = y[7+latent_stages]
    VOL = 1
    s = 0.1
    tmod <- t %% 365.0
    
    immigration = ImmigrationRate / 2 * (erf((tmod - 100) / s) - erf((tmod - (100 + ImmigrationPeriod)) / s))

    #ifelse(t %% 365 > 100 & t %% 365 < 100 + ImmigrationPeriod,ImmigrationRate,0) 
    
    fishing = FishingRate - FishingRate/2*(erf((tmod - 100)/s) - erf((tmod - (100+ImmigrationPeriod))/s))
    
    #ifelse(t %% 365 <= 100 | t %% 365 >= 100 + ImmigrationPeriod, FishingRate, 0)
    
    Pred_A = f*Preds/(1 + f*h*(A + sum(Es) + I + f_J*h_J*J + f_N*h_N*N)/VOL  + i_P*max(Preds-1, 0)/VOL)
    Pred_J = f*f_J*Preds/(1 + f*h*(A + sum(Es) + I  + f_J*h_J*J + f_N*h_N*N)/VOL  + i_P*max(Preds-1, 0)/VOL)
    Pred_N = f*f_N*Preds/(1 + f*h*(A + sum(Es) + I + f_J*h_J*J + f_N*h_N*N)/VOL  + i_P*max(Preds-1, 0)/VOL)
    
    d_A_c = d_A*exp(comp_d / VOL * (c_N * N + c_J * J + A + sum(Es))) #density dependence in deaths
    
    d_J_c = d_J*exp(comp_d / VOL * (c_N * N + c_J * J + A + sum(Es))) #density dependence in deaths
    
    d_N_c = d_N*exp(comp_d / VOL * (c_N * N + c_J * J + A + sum(Es))) #density dependence in deaths
    
    m_N_c = m_N*exp(-comp_m/VOL*(c_N*N + c_J*J + A + sum(Es))) #density dependence in maturation
    
    m_J_c = m_J*exp(-comp_m/VOL*(c_N*N + c_J*J + A + sum(Es))) #density dependence in maturation
    
    dNdt = b_M*(A + sum(Es))/2*exp(-comp_b/VOL*(c_N*N + c_J*J + A + sum(Es))) - (m_N_c+d_N_c)*N - cann*(A + I + sum(Es))*N - Pred_N*N
    
    dJdt = m_N_c*N - (m_J_c+d_J_c)*J -Pred_J*J
    
    dAdt = m_J_c*J - d_A_c*A - lambda*A - Pred_A*A
    
    # development of all stages
    latent_progression = latent_rate*Es
    # lost to next stage   #death      #gained from last stage
    dEsdt = -latent_progression - d_A_c*Es + c(lambda*A, latent_progression[1:(latent_stages - 1)]) - Pred_A*Es
    
    dIdt = as.numeric(latent_progression[latent_stages]) - d_A_c*I - Pred_A*I
    
    dPredsdt = Preds*(convEff*(Pred_N*N + Pred_J*J + Pred_A*A + Pred_A*sum(Es))) - d_F*Preds + immigration - fishing*Preds   #conv eff should be based on size class
    
    dL3Fdt <- Pred_A*I - d_W*L3F -fishing*L3F #- d_F*L3F/Preds 
    
    dHEFdt <- fishing*L3F 
    
    result = c(dNdt,dJdt,dAdt, dEsdt, dIdt,dPredsdt, dL3Fdt, dHEFdt)
    
    
    return(list(result))
  }
  )
}

```



```{r}
#bring in mcmc chains
setwd("~/Desktop/Rscripts/Data/Fish")
get_best_fit = function(chain.list){
  L = length(chain.list)
  chain.scores = numeric()
  for(i in 1:L){
    chain.scores[i] = max(chain.list[[i]]$log.p)
  }
  list(chain.list[[which.max(chain.scores)]]$samples[which.max(chain.list[[which.max(chain.scores)]]$log.p),],
       chain.list[[which.max(chain.scores)]]$cov.jump)
  
}


#bring in 24 mcmc chains
#bring in 24 mcmc chains
setwd("~/Desktop/Rscripts/Data/Fish")
chainsA <- readRDS("Joint_GW_full_A2_2.RDA")
chainsB <- readRDS("Joint_GW_full_B2_2.RDA")
chainsC <- readRDS("Joint_GW_full_C2_2.RDA")

#remove chains that did not converge
chainsAconverged = chainsA[-c(1:3)]
chainsBconverged = chainsB[-c(2)]
chainsCconverged = chainsC[-c(1,6,7)]

#combine converged chains
fishchains = c(chainsAconverged,chainsBconverged,chainsCconverged)

#combine converged chains
fishchains = c(chainsAconverged,chainsBconverged,chainsCconverged)

#get best fit
get_best_fit = function(chain.list){
  L = length(chain.list)
  chain.scores = numeric()
  for(i in 1:L){
    chain.scores[i] = max(chain.list[[i]]$log.p)
  }
  list(chain.list[[which.max(chain.scores)]]$samples[which.max(chain.list[[which.max(chain.scores)]]$log.p),],
       chain.list[[which.max(chain.scores)]]$cov.jump,
       max(chain.list[[which.max(chain.scores)]]$log.p))
  
}

pomp_parameter_trans = function(x){
  log_par_names = c("comp_d", "comp_b", "comp_m", "cann")
  x[log_par_names] = exp(x[log_par_names])
  x
}
pomp_parameter_backtrans = function(x){
  log_par_names = c("comp_d", "comp_b", "comp_m", "cann")
  x[log_par_names] = log(x[log_par_names])
  x
}

samps = get_best_fit(fishchains)
parameters = pomp_parameter_trans(samps[[1]])

hist(data.frame(fishchains[[4]]$samples)$d_A)

variances = get_best_fit(fishchains)[[2]] 

parameters["latent_stages"] = 60
parameters["latent_rate"] = 4.3
parameters["lambda"] = 0.032
parameters["d_W"] = 0.01 #on average GW in fish live 100 days 
parameters["d_F"] = 0
parameters["convEff"] = 0 #how many fish can you build by eating one adult, temper for nauplii and juveniles (mass of n/mass over a)
parameters["ImmigrationRate"] = 0.375/50 #fish per liter per day 
parameters["FishingRate"] = 0.143 #fish fished per liter per day (fishing effort) - the average fish is caught after 1 week (1/7)
parameters["ImmigrationPeriod"] = 50
parameters = unlist(parameters)


Exposed_names = paste0("E", 1:parameters["latent_stages"])
Exposed_values = rep(0, times=parameters["latent_stages"])
names(Exposed_values) = Exposed_names
Exposed_values

#E1 <- Exposed_values[1]
#Exposed_values = Exposed_values[2:60]

Inits = c(N = 7500, J = 6000, A = 700, Exposed_values, I = 0, Preds = 0,L3F = 0, HEF = 0)/15 #E1 = 15
timespan = 365*2

sim1 = data.frame(ode(y = Inits, times=1:timespan, parms=parameters, hmax=1,
                         method="lsoda", func=Pond_ODE)) 

#sim1[,"Es"] = rowSums(sim1) - sim1[,"N"] - sim1[,"J"]- sim1[,"A"] - sim1[,"I"] - sim1[,"time"] - sim1[,"L3F"] - sim1[,"HEF"] - sim1["Preds"]

sim1Es = data.frame(rowSums(sim1[, c(5:64)])) 

colnames(sim1Es) = "Es"

sim1Es = sim1Es %>% mutate(time = row_number())

ggplot(data = sim1Es, aes(x=time,y=Es)) + geom_line() + xlim(0,200)


plot(I~ time, sim1)
plot(E60~ time, sim1)



```



```{r plot population dynamics}
#create a data frame from simulation output for graphing 
#check that simulation is doing what we expect 
# 
# fish = dim(sim1)[1]
# 
# PARAM = rep(colnames(sim1)[-1], each=fish)
# Jul.date = rep(sim1[,1], times = length(colnames(sim1)[-1]))
# Counts = c(sim1[,-1])
# 
# prediction.df = data.frame(PARAM, Jul.date, Counts)
# 
# #sum all E columns
# prediction.df.sumexposed = prediction.df %>% 
#   filter(grepl("E", PARAM)) %>% # Filter rows where 'PARAM' contains 'E'
#   group_by(Jul.date) %>%    # Group by julian date
#   summarise(Counts = sum(Counts)) %>% # Summarize by summing Counts 
#   mutate(PARAM = "E")

# prediction.df.summarized = rbind(prediction.df,prediction.df.sumexposed) %>% filter(PARAM %in% c("N","J","A","E","I","L3F","Preds","HEF")) 
# 
# prediction.df.summarized.denom = rbind(prediction.df,prediction.df.sumexposed) %>% filter(PARAM %in% c("A","E","I")) %>% group_by(Jul.date) %>% summarise(denominator = sum(Counts))
# 
# 
# prediction.df.summarized.I = prediction.df.summarized %>% filter(PARAM == "I")
# 
# prediction.df.summarized.I = prediction.df.summarized.I %>% mutate(prevelance = prediction.df.summarized.I$Counts/prediction.df.summarized.denom$denominator)
# 
# ggplot(data=prediction.df.summarized.I, aes(x=Jul.date, y=prevelance)) + 
#          geom_line(size = 1.4) + labs(y = "prevelance", x = "Julian Date") + ylim(c(0,0.2))
# 
# 
# p.plot <- ggplot(data=prediction.df.summarized, aes(x=Jul.date, y=Counts, group=PARAM, colour=PARAM)) + 
#          geom_line(size = 1.4) + labs(y = "Counts", x = "Julian Date") 
# p.plot + ylim(0,100)

sim1long = sim1 %>%
  pivot_longer(
    cols = c(2:68),
    names_to = "PARAM",
    values_to = "Counts"
  )


#plot Es 
sim1longEs = sim1long %>% filter(grepl("E", PARAM)) 
sim1longI = sim1long %>% filter(grepl("I", PARAM)) 

sim1longEs = sim1longEs %>% filter(PARAM != "HEF")

data = rbind(sim1longEs,sim1longI)

p.plot.Es <- ggplot(data=data, aes(x=time, y=Counts, group=PARAM, colour=PARAM)) + 
         geom_line(size = 1.4) + labs(y = "Counts", x = "time") + xlim(0,150)

p.plot.Es + xlim(0,20) + ylim(0,1) 


ggplot(data=data%>%filter(PARAM %in% c("I","E60")), aes(x=time, y=Counts, group=PARAM, colour=PARAM)) + 
         geom_line(size = 1.4) + labs(y = "Counts", x = "time") +xlim(0,15)
```


```{r set new plot functions for sensobol}
#function sandra_plot_scatter alters the graph output of the sensobol function to be more visually pleasing to Sandra
#run this before running sensobol 

library(ggplot2)

plot_names <- c('ImmigrationPeriod' = "ImmigrationPeriod",
                'ImmigrationRate' = "ImmigrationRate",
                'FishingRate' = "FishingRate")

axis_titles <- data.frame(
  variable = c("ImmigrationPeriod", "ImmigrationRate", "FishingRate"),
  axis_title = c("Fold increase in \n Immigration Period", "Fold increase in \n Immigration Rate", "Fold increase in \n Fishing Rate")
)


sandra_plot_scatter = function (data, N, Y, params, method = "point", size = 0.7, 
  alpha = 0.2) 
{
  value <- y <- NULL
  minY <- min(Y)
  print(minY)
  dt <- data.table::data.table(cbind(data, Y))[1:N]
  colnames(dt)[length(colnames(dt))] <- "y"
  out <- data.table::melt(dt, measure.vars = params)
  gg <- ggplot2::ggplot(out, ggplot2::aes(value, y)) + 
    ggplot2::facet_wrap(~variable, scales = "free_x", labeller = as_labeller(plot_names, default = label_parsed))  + 
    ggplot2::labs(x = NULL, y = "Mean infection prevalence curve") + 
    ggplot2::theme_bw() + 
    ggplot2::theme(panel.grid.major = ggplot2::element_blank(),
                   panel.spacing = unit(1.25, "lines"), #add more space between panels
                  panel.grid.minor = ggplot2::element_blank(), legend.background = ggplot2::element_rect(fill = "transparent", 
                  color = NA), legend.key = ggplot2::element_rect(fill = "transparent", 
                  color = NA), strip.background = ggplot2::element_rect(fill = "white"), 
                  strip.text = element_text(size = 14), legend.position = "top",
                  plot.margin = unit(c(.5,.1,.75,.5), "cm"),
                  axis.title=element_text(size=14), axis.text = element_text(size = 12)) + 
    ggplot2::geom_text(data = axis_titles, aes(label = axis_title), size = 4.5, 
                       x= c(min(dt$ImmigrationPeriod) + diff(range(dt$ImmigrationPeriod))/2, min(dt$ImmigrationRate) + diff(range(dt$ImmigrationRate))/2, min(dt$FishingRate) + diff(range(dt$FishingRate))/2) ,  #centers x axis labels for individual graphs, variables hardcoded, need to change if using diff ones
                       y= minY - diff(range(Y))/4, color='black') + # need to change y to the minimal value - some divider x Y's range
    coord_cartesian(clip="off")
  if (method == "point") {
    gg <- gg + ggplot2::geom_point(size = size, alpha = alpha) + 
      ggplot2::stat_summary_bin(fun = "mean", geom = "point", 
        colour = "red", size = 1.2)
  }
  else if (method == "bin") {
    gg <- gg +  ggplot2::geom_hex(bins = 35) + scale_fill_viridis_c() + #scale_colour_gradient2(palette = "viridis") +
      ggplot2::stat_summary_bin(fun = "mean", geom = "line", colour = "red", size = 1.2)
  }
  else {
    stop("Method should be either point or bin")
  }
  return(gg)
}


#another mod to graphing defaults 

library(RColorBrewer)

sandra_plot_multiscatter = function (data, N, Y, params, smpl = NULL) 
{
    xvar <- yvar <- x <- y <- NULL
    dt <- data.table::data.table(data)
    out <- t(utils::combn(params, 2))
    da <- list()
    for (i in 1:nrow(out)) {
        cols <- out[i, ]
        da[[i]] <- cbind(dt[1:N, .SD, .SDcols = (cols)], cols[1], 
            cols[2], Y[1:N])
        data.table::setnames(da[[i]], colnames(da[[i]]), c("xvar", 
            "yvar", "x", "y", "output"))
    }
    output <- data.table::rbindlist(da)
    if (is.null(smpl) == FALSE) {
        if (is.numeric(smpl) == FALSE) {
            stop("smpl should be a number")
        }
        else {
            output <- output[, .SD[sample(.N, min(smpl, .N))], 
                by = list(x, y)]
        }
    }
    gg <- ggplot2::ggplot(output, ggplot2::aes(xvar, yvar, color = output)) + 
        ggplot2::geom_point(size = 0.5) + ggplot2::scale_colour_gradientn(colours = grDevices::hcl.colors(7, palette = "viridis")) + 
        ggplot2::scale_x_continuous(breaks = scales::pretty_breaks(n = 3)) + 
        ggplot2::scale_y_continuous(breaks = scales::pretty_breaks(n = 3)) + 
        ggplot2::facet_wrap(x ~ y, scales = "free") + ggplot2::theme_bw() + 
        ggplot2::labs(x = "", y = "") + ggplot2::theme(panel.grid.major = ggplot2::element_blank(), 
        panel.grid.minor = ggplot2::element_blank(), legend.background = ggplot2::element_rect(fill = "transparent", 
            color = NA), legend.key = ggplot2::element_rect(fill = "transparent", 
            color = NA), strip.background = ggplot2::element_rect(fill = "white"), 
        legend.position = "top")
    return(gg)
}

```


```{r sensobol graphs, fig.show = 'hold'} 
N <- 2^13 #number of parameter combinations (recommendation from paper outlining the sensobol package)
pars <- c( "ImmigrationPeriod", "ImmigrationRate", "FishingRate") # Choose parameters of interest
matrices <- c("A", "B", "AB", "BA") #recommendation from paper for specific analysis of interest (variation partitioning approach)
first <- total <- "azzini"
order <- "second" #what level of interactions are allowed 
R<-10^3 
type<-"percent"
conf<-0.95

mat <- sobol_matrices(matrices=matrices, N = N, params = pars, order = order) #creates different matrices with parameter combinations (based on quantiles)

# Choose their ranges
  #you have to pick the uniform because of how the sobol sensitivity is formulated 
mat[, "ImmigrationPeriod"] <- qunif(mat[, "ImmigrationPeriod"], 10, 182) #units in days 
mat[, "ImmigrationRate"] <- qunif(mat[, "ImmigrationRate"], 0.025/50, 0.5/50) #fish per liter per day
mat[, "FishingRate"] <- qunif(mat[, "FishingRate"], 0, 0.143) #fish fished per liter per day (fishing effort) - the average fish is caught between 1 week and the fish are never caught 


sobol_fxn = function(ImmigrationPeriod,ImmigrationRate,FishingRate) { # Runs the model and calculates area under the prevalence curve (similar to a forloop)
parameters["ImmigrationPeriod"] = ImmigrationPeriod; parameters["ImmigrationRate"] = ImmigrationRate; parameters["FishingRate"] = FishingRate;
  sim = ode(y = Inits, times=1:timespan, parms=parameters, hmax=1,
                         method="lsoda", func=Pond_ODE) 
  
  
  # Extract HEF values at the required days
  hef_731  <- sim[sim[,"time"] == 731,  "HEF"] #first day of 3rd year
  hef_1825 <- sim[sim[,"time"] == 1825, "HEF"] #last day of 5th year 
  
  HEF_diff <- hef_1825 - hef_731

  # Select days 731â€“1825
  sel <- sim[,"time"] >= 731 & sim[,"time"] <= 1825 # other way to do: sel <- 731:1825

  #print(sel)
  
  #print(sim[sel, "I"])
  

return(list(c(
    mean_L3F = mean(sim[sel, "L3F"], na.rm = TRUE),
    mean_I   = mean(sim[sel, "I"],   na.rm = TRUE),
    HEF = as.numeric(HEF_diff) 
  ))) } 


sobol_fxn(ImmigrationPeriod = parameters["ImmigrationPeriod"],ImmigrationRate = parameters["ImmigrationRate"], FishingRate = parameters["FishingRate"])

sobol_mapply_fxn = function(dt){
  return(mapply(sobol_fxn, dt[, 1], dt[, 2], dt[, 3])) } #each column in the dataframe is a parameter vector 

# mat = our inputs
# result = our model outputs
result = sobol_mapply_fxn(mat)
df = as.data.frame(do.call(rbind, result))
full.dt = data.table(mat, df) 

plot_uncertainty(Y = full.dt$mean_L3F, N = N) + labs(y = "Mean L3F", x = "y")
plot_uncertainty(Y = full.dt$mean_I, N = N) + labs(y = "Mean I", x = "y")
plot_uncertainty(Y = full.dt$HEF, N = N) + labs(y = "HEF", x = "y")


for (output in c("mean_L3F", "mean_I", "HEF")) {
  Yvals <- full.dt[[output]]
  
  # Scatter/facet plot
  p1 <- sandra_plot_scatter(data = full.dt, N = N, Y = Yvals, params = pars, method = "bin")
  print(p1)
  
  # Pairwise multiscatter
  p2 <- sandra_plot_multiscatter(data = full.dt, N = N, Y = Yvals, params = pars, smpl = 2^13)
  print(p2)
}

indL3F <- sobol_indices(matrices = matrices, Y = df$mean_L3F, N = N, params = pars, 
                     first = first, total = total, order = order, boot = TRUE, R = R,
                     parallel = "no", type = type, conf = conf)

indL3F

indI <- sobol_indices(matrices = matrices, Y = df$mean_I, N = N, params = pars, 
                     first = first, total = total, order = order, boot = TRUE, R = R,
                     parallel = "no", type = type, conf = conf)

indI

indHEF <- sobol_indices(matrices = matrices, Y = df$HEF, N = N, params = pars, 
                     first = first, total = total, order = order, boot = TRUE, R = R,
                     parallel = "no", type = type, conf = conf)

indHEF


toplot.L3F <- subset(indL3F$results, parameters=="ImmigrationPeriod" | parameters=="ImmigrationRate" | parameters=="FishingRate")
toplot.I <- subset(indI$results, parameters=="ImmigrationPeriod" | parameters=="ImmigrationRate" | parameters=="FishingRate")
toplot.HEF <- subset(indHEF$results, parameters=="ImmigrationPeriod" | parameters=="ImmigrationRate" | parameters=="FishingRate")

```

```{r sobol indices graphs, fig.show = 'hold'}


plot(indL3F)
plot(indI)
plot(indHEF)



#make plots nicer
indL3Fp1 <- ggplot(toplot.L3F, aes(x=parameters, y=original, fill=sensitivity)) + 
  geom_bar(stat="identity", color="black", position=position_dodge()) +
  scale_fill_manual(name = "Effects", labels = c("Individual", "Total"), values=c("grey",
                             "gray42")) +
  geom_linerange(aes(ymin=original-std.error, ymax=original+std.error), linewidth= 1.5,
                 position=position_dodge(.9)) +
   theme(legend.position = "top", legend.justification = "center") +
  scale_y_continuous(limits = c(0, 1), expand = c(0,0)) +
  labs(y = "Index Value", x = "") + ggtitle("L3s in Fish")

indL3Fp1

indIp2 <- ggplot(toplot.I, aes(x=parameters, y=original, fill=sensitivity)) + 
  geom_bar(stat="identity", color="black", position=position_dodge()) +
  scale_fill_manual(name = "Effects", labels = c("Individual", "Total"), values=c("grey",
                             "gray42")) +
  geom_linerange(aes(ymin=original-std.error, ymax=original+std.error), linewidth= 1.5,
                 position=position_dodge(.9)) +
   theme(legend.position = "top", legend.justification = "center") +
  scale_y_continuous(limits = c(0, 1), expand = c(0,0)) +
  labs(y = "Index Value", x = "") + ggtitle("Infectious Copepods")

indIp2 

#total effect indices,  account for interaction effects among our three parameters of interest.
```






